{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8bf38e",
   "metadata": {},
   "source": [
    "# üìä Notebook 01: Data Pipeline & Preprocessing\n",
    "\n",
    "## AADHAAR INTELLIGENCE SYSTEM - UIDAI Hackathon 2025-26\n",
    "\n",
    "---\n",
    "\n",
    "### Objective\n",
    "Extract, transform, and load the **3 Real UIDAI Datasets** for behavioral analytics:\n",
    "1. **Enrollment Data** - New Aadhaar registrations by age group (0-5, 5-17, 18+)\n",
    "2. **Demographic Update Data** - Address/Name updates by age group\n",
    "3. **Biometric Update Data** - Fingerprint/Iris updates by age group\n",
    "\n",
    "### Dataset Structure\n",
    "- **Enrolment**: `date, state, district, pincode, age_0_5, age_5_17, age_18_greater`\n",
    "- **Demographic**: `date, state, district, pincode, demo_age_5_17, demo_age_17_`\n",
    "- **Biometric**: `date, state, district, pincode, bio_age_5_17, bio_age_17_`\n",
    "\n",
    "### Output\n",
    "- Cleaned, merged master dataset\n",
    "- Data quality report\n",
    "- Export for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 1: Import Libraries\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"üìÖ Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"üêç Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 2: Configuration & Paths\n",
    "# ============================================\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = '../data/'\n",
    "OUTPUT_DIR = '../outputs/'\n",
    "\n",
    "# Dataset folder paths (extracted from zip files)\n",
    "DATASET_PATHS = {\n",
    "    'enrolment': f\"{DATA_DIR}enrolment/\",\n",
    "    'demographic': f\"{DATA_DIR}demographic/\",\n",
    "    'biometric': f\"{DATA_DIR}biometric/\"\n",
    "}\n",
    "\n",
    "# Create output directory if not exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/charts\", exist_ok=True)\n",
    "\n",
    "print(\"üìÅ Configuration set:\")\n",
    "print(f\"   Data Directory: {DATA_DIR}\")\n",
    "print(f\"   Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nüìÇ Dataset Paths:\")\n",
    "for name, path in DATASET_PATHS.items():\n",
    "    print(f\"   ‚Ä¢ {name}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ea647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 3: Data Loading Function\n",
    "# ============================================\n",
    "\n",
    "def load_all_csvs(folder_path, dataset_name):\n",
    "    \"\"\"\n",
    "    Load and concatenate all CSV files from a folder\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    folder_path : str - Path to folder containing CSVs\n",
    "    dataset_name : str - Name for logging\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame - Concatenated dataset\n",
    "    \"\"\"\n",
    "    print(f\"\\nüì¶ Loading: {dataset_name.upper()}\")\n",
    "    print(f\"   Path: {folder_path}\")\n",
    "    \n",
    "    # Find all CSV files recursively\n",
    "    all_files = glob.glob(os.path.join(folder_path, \"**/*.csv\"), recursive=True)\n",
    "    \n",
    "    if not all_files:\n",
    "        print(f\"   ‚ö†Ô∏è No CSV files found in {folder_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"   üìÑ Found {len(all_files)} CSV files\")\n",
    "    \n",
    "    # Load and concatenate all CSVs\n",
    "    dfs = []\n",
    "    total_rows = 0\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "        total_rows += len(df)\n",
    "        print(f\"      ‚úì {os.path.basename(file)}: {len(df):,} rows\")\n",
    "    \n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"   ‚úÖ Total loaded: {len(combined_df):,} records\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "print(\"‚úÖ Data loading function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae777d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 4: Load All 3 UIDAI Datasets\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîÑ LOADING REAL UIDAI DATASETS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load Enrolment Data\n",
    "df_enrolment = load_all_csvs(DATASET_PATHS['enrolment'], 'enrolment')\n",
    "\n",
    "# Load Demographic Update Data  \n",
    "df_demographic = load_all_csvs(DATASET_PATHS['demographic'], 'demographic')\n",
    "\n",
    "# Load Biometric Update Data\n",
    "df_biometric = load_all_csvs(DATASET_PATHS['biometric'], 'biometric')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ALL DATASETS LOADED SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìà Dataset Summary:\")\n",
    "print(f\"   Enrolment Records: {len(df_enrolment):,}\")\n",
    "print(f\"   Demographic Records: {len(df_demographic):,}\")\n",
    "print(f\"   Biometric Records: {len(df_biometric):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 5: Data Exploration\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüîç DATA EXPLORATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display column info for each dataset\n",
    "print(\"\\nüìã ENROLMENT DATA:\")\n",
    "print(f\"   Columns: {df_enrolment.columns.tolist()}\")\n",
    "print(f\"   Shape: {df_enrolment.shape}\")\n",
    "display(df_enrolment.head(3))\n",
    "\n",
    "print(\"\\nüìã DEMOGRAPHIC UPDATE DATA:\")\n",
    "print(f\"   Columns: {df_demographic.columns.tolist()}\")\n",
    "print(f\"   Shape: {df_demographic.shape}\")\n",
    "display(df_demographic.head(3))\n",
    "\n",
    "print(\"\\nüìã BIOMETRIC UPDATE DATA:\")\n",
    "print(f\"   Columns: {df_biometric.columns.tolist()}\")\n",
    "print(f\"   Shape: {df_biometric.shape}\")\n",
    "display(df_biometric.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6339877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 6: Data Preprocessing\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüßπ DATA PREPROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert date columns\n",
    "df_enrolment['date'] = pd.to_datetime(df_enrolment['date'], format='%d-%m-%Y')\n",
    "df_demographic['date'] = pd.to_datetime(df_demographic['date'], format='%d-%m-%Y')\n",
    "df_biometric['date'] = pd.to_datetime(df_biometric['date'], format='%d-%m-%Y')\n",
    "\n",
    "# Calculate total enrollments per record\n",
    "df_enrolment['total_enrolments'] = df_enrolment['age_0_5'] + df_enrolment['age_5_17'] + df_enrolment['age_18_greater']\n",
    "\n",
    "# Fix column names (strip trailing characters)\n",
    "df_demographic.columns = df_demographic.columns.str.strip('_')\n",
    "df_biometric.columns = df_biometric.columns.str.strip('_')\n",
    "\n",
    "# Rename columns for consistency\n",
    "if 'demo_age_17' in df_demographic.columns:\n",
    "    df_demographic.rename(columns={'demo_age_17': 'demo_age_18_greater'}, inplace=True)\n",
    "if 'bio_age_17' in df_biometric.columns:\n",
    "    df_biometric.rename(columns={'bio_age_17': 'bio_age_18_greater'}, inplace=True)\n",
    "\n",
    "# Calculate totals for demographic and biometric\n",
    "df_demographic['total_demo_updates'] = df_demographic.filter(like='demo_age').sum(axis=1)\n",
    "df_biometric['total_bio_updates'] = df_biometric.filter(like='bio_age').sum(axis=1)\n",
    "\n",
    "# Add derived date columns\n",
    "for df in [df_enrolment, df_demographic, df_biometric]:\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "\n",
    "print(\"‚úÖ Date columns converted to datetime\")\n",
    "print(f\"   Enrolment date range: {df_enrolment['date'].min()} to {df_enrolment['date'].max()}\")\n",
    "print(f\"   Demographic date range: {df_demographic['date'].min()} to {df_demographic['date'].max()}\")\n",
    "print(f\"   Biometric date range: {df_biometric['date'].min()} to {df_biometric['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 7: Data Quality Report\n",
    "# ============================================\n",
    "\n",
    "def data_quality_report(df, name):\n",
    "    \"\"\"Generate comprehensive data quality report\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìã DATA QUALITY REPORT: {name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nüìä BASIC STATISTICS:\")\n",
    "    print(f\"   Total Records: {len(df):,}\")\n",
    "    print(f\"   Total Columns: {len(df.columns)}\")\n",
    "    print(f\"   Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nüìù COLUMN INFORMATION:\")\n",
    "    for col in df.columns:\n",
    "        null_pct = df[col].isnull().sum() / len(df) * 100\n",
    "        unique = df[col].nunique()\n",
    "        dtype = df[col].dtype\n",
    "        print(f\"   ‚Ä¢ {col}: {dtype} | Unique: {unique:,} | Null: {null_pct:.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'name': name,\n",
    "        'records': len(df),\n",
    "        'columns': len(df.columns),\n",
    "        'null_pct': df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100\n",
    "    }\n",
    "\n",
    "# Generate reports for all datasets\n",
    "quality_reports = []\n",
    "quality_reports.append(data_quality_report(df_enrolment, 'Enrollment'))\n",
    "quality_reports.append(data_quality_report(df_demographic, 'Demographic'))\n",
    "quality_reports.append(data_quality_report(df_biometric, 'Biometric'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 8: Create Pincode-Level Master Dataset\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüìç CREATING PINCODE-LEVEL MASTER DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Aggregate enrollment by pincode\n",
    "enrolment_by_pincode = df_enrolment.groupby(['state', 'district', 'pincode']).agg({\n",
    "    'age_0_5': 'sum',\n",
    "    'age_5_17': 'sum',\n",
    "    'age_18_greater': 'sum',\n",
    "    'total_enrolments': 'sum',\n",
    "    'date': 'count'\n",
    "}).reset_index()\n",
    "enrolment_by_pincode.rename(columns={'date': 'enrolment_days'}, inplace=True)\n",
    "\n",
    "# Aggregate demographic updates by pincode\n",
    "demo_by_pincode = df_demographic.groupby(['state', 'district', 'pincode']).agg({\n",
    "    'total_demo_updates': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Aggregate biometric updates by pincode\n",
    "bio_by_pincode = df_biometric.groupby(['state', 'district', 'pincode']).agg({\n",
    "    'total_bio_updates': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge all datasets\n",
    "master_pincode = enrolment_by_pincode.merge(\n",
    "    demo_by_pincode[['pincode', 'total_demo_updates']], \n",
    "    on='pincode', \n",
    "    how='left'\n",
    ").merge(\n",
    "    bio_by_pincode[['pincode', 'total_bio_updates']], \n",
    "    on='pincode', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values\n",
    "master_pincode['total_demo_updates'] = master_pincode['total_demo_updates'].fillna(0)\n",
    "master_pincode['total_bio_updates'] = master_pincode['total_bio_updates'].fillna(0)\n",
    "\n",
    "# Calculate total activity\n",
    "master_pincode['total_activity'] = (\n",
    "    master_pincode['total_enrolments'] + \n",
    "    master_pincode['total_demo_updates'] + \n",
    "    master_pincode['total_bio_updates']\n",
    ")\n",
    "\n",
    "# Calculate daily rate\n",
    "master_pincode['daily_enrolment_rate'] = master_pincode['total_enrolments'] / master_pincode['enrolment_days']\n",
    "\n",
    "print(f\"\\nüìä Master Pincode Dataset Created:\")\n",
    "print(f\"   Total Unique Pincodes: {len(master_pincode):,}\")\n",
    "print(f\"   Total States/UTs: {master_pincode['state'].nunique()}\")\n",
    "print(f\"   Total Enrolments: {master_pincode['total_enrolments'].sum():,}\")\n",
    "print(f\"   Total Demo Updates: {master_pincode['total_demo_updates'].sum():,.0f}\")\n",
    "print(f\"   Total Bio Updates: {master_pincode['total_bio_updates'].sum():,.0f}\")\n",
    "\n",
    "display(master_pincode.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8102270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 9: Data Summary Visualization\n",
    "# ============================================\n",
    "\n",
    "# Create summary visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Enrollments by State (Top 10)', \n",
    "        'Age Group Distribution',\n",
    "        'Monthly Enrollment Trend',\n",
    "        'Daily Activity Pattern'\n",
    "    ),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}],\n",
    "           [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    ")\n",
    "\n",
    "# Plot 1: Enrollments by State\n",
    "state_enrol = master_pincode.groupby('state')['total_enrolments'].sum().sort_values(ascending=True).tail(10)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=state_enrol.values, y=state_enrol.index, orientation='h', \n",
    "           marker_color='#FF6B35', name='Enrollments'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot 2: Age Group Distribution\n",
    "age_totals = {\n",
    "    '0-5 years': df_enrolment['age_0_5'].sum(),\n",
    "    '5-17 years': df_enrolment['age_5_17'].sum(),\n",
    "    '18+ years': df_enrolment['age_18_greater'].sum()\n",
    "}\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=list(age_totals.keys()), values=list(age_totals.values()),\n",
    "           marker_colors=['#1B998B', '#F77F00', '#D62828']),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Plot 3: Monthly Trend\n",
    "monthly = df_enrolment.groupby(['year', 'month'])['total_enrolments'].sum().reset_index()\n",
    "monthly['date'] = pd.to_datetime(monthly[['year', 'month']].assign(day=1))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=monthly['date'], y=monthly['total_enrolments'], mode='lines+markers',\n",
    "               line_color='#1B998B', name='Trend'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot 4: Daily Activity Pattern\n",
    "daily_pattern = df_enrolment.groupby('day_of_week')['total_enrolments'].sum()\n",
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "fig.add_trace(\n",
    "    go.Bar(x=days, y=daily_pattern.values, marker_color='#004E89', name='Daily'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='<b>AADHAAR DATA PIPELINE SUMMARY</b>',\n",
    "    title_x=0.5,\n",
    "    height=700,\n",
    "    showlegend=False,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Save figure\n",
    "fig.write_html(f\"{OUTPUT_DIR}/charts/01_data_pipeline_summary.html\")\n",
    "print(\"üìä Chart saved to outputs/charts/01_data_pipeline_summary.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12a98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 10: Export Processed Data\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüíæ EXPORTING PROCESSED DATASETS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save cleaned datasets\n",
    "df_enrolment.to_csv(f\"{OUTPUT_DIR}/enrolment_cleaned.csv\", index=False)\n",
    "df_demographic.to_csv(f\"{OUTPUT_DIR}/demographic_cleaned.csv\", index=False)\n",
    "df_biometric.to_csv(f\"{OUTPUT_DIR}/biometric_cleaned.csv\", index=False)\n",
    "master_pincode.to_csv(f\"{OUTPUT_DIR}/master_pincode.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Exported files:\")\n",
    "print(f\"   ‚Ä¢ enrolment_cleaned.csv ({len(df_enrolment):,} records)\")\n",
    "print(f\"   ‚Ä¢ demographic_cleaned.csv ({len(df_demographic):,} records)\")\n",
    "print(f\"   ‚Ä¢ biometric_cleaned.csv ({len(df_biometric):,} records)\")\n",
    "print(f\"   ‚Ä¢ master_pincode.csv ({len(master_pincode):,} pincodes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5281a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 11: Pipeline Metrics Summary\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FINAL PIPELINE METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_records = len(df_enrolment) + len(df_demographic) + len(df_biometric)\n",
    "\n",
    "metrics = {\n",
    "    'Total Records Processed': f\"{total_records:,}\",\n",
    "    'Unique Pincodes': f\"{len(master_pincode):,}\",\n",
    "    'Total States/UTs': f\"{master_pincode['state'].nunique()}\",\n",
    "    'Total Enrollments': f\"{master_pincode['total_enrolments'].sum():,}\",\n",
    "    'Total Demographic Updates': f\"{master_pincode['total_demo_updates'].sum():,.0f}\",\n",
    "    'Total Biometric Updates': f\"{master_pincode['total_bio_updates'].sum():,.0f}\",\n",
    "    'Age 0-5 Enrollments': f\"{df_enrolment['age_0_5'].sum():,}\",\n",
    "    'Age 5-17 Enrollments': f\"{df_enrolment['age_5_17'].sum():,}\",\n",
    "    'Age 18+ Enrollments': f\"{df_enrolment['age_18_greater'].sum():,}\",\n",
    "    'Date Range': f\"{df_enrolment['date'].min().date()} to {df_enrolment['date'].max().date()}\"\n",
    "}\n",
    "\n",
    "for key, value in metrics.items():\n",
    "    print(f\"   ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ NOTEBOOK 01 COMPLETE - Proceed to 02_life_events.ipynb\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
